<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h1>Machine Learning</h1>

    <!-- Navigation Bar -->
    <nav>
        <table class="nav-list">
            <td><a href="index.html">Home</a></td>
            <td><a href="aboutus.html">About Us</a></td>
            <td><a href="resources.html">Resources</a></td>
            <td><a href="techhero.html">Tech Heroes</a></td>
            <td><a href="ourmachine.html">Machine Learning</a></td>
            
        </table>
    </nav>

    <nav>  <!--Sub Navigation for Machine Learning Page-->

        <a href="ourmachine.html"><button class="MLA-But">Try Our Model</button></a>
        <a href="Objective.html"> <button class="MLA-But">Objective</button></a>
        <a href="Process.html"> <button class="MLA-But">Process</button></a>
        <a href="BuolamwinisWork.html"><button class="MLA-But">Buolamwini's Work</button></a>
        <a href="LessonsLearned.html"> <button class="MLA-But">Lessons Learned</button></a>
        <a href="MLvideo.html"><button class="MLA-But">Video Example</button></a>

    </nav>
    <br>
   
    
    <div class="ML-Words">  <!--Description of Connecting to Buolamwini's Work-->
      <h2>Connecting to Buolamwini's Work</h2>
    <br>  
    <p>Joy Buolamwini’s research provided a powerful framework for critically reflecting on our model. In Unmasking AI, she recounts her experience with facial recognition software that failed to accurately identify darker-skinned women while performing much better on lighter-skinned men. This was due to bias in the training data, which overwhelmingly featured lighter-skinned male faces. As she was studying facial recognition technologies, she stated, “Skewed gold standard benchmark datasets led to a false sense of universal progress based on assessing the performance of facial recognition technologies on only a small segment of humanity” (Buolamwini 98). Our project revealed a similar pattern. When our model saw a spiky ball with an ipad, it had no contextual understanding, it simply guessed based on a surface-level training.
</p>
    <p>Even in our simple origami classification, the decision of what categories to include shaped the model’s performance and perspective. In reflecting on these limitations, Buolamiwini demonstrated how there is cost inclusion and exclusion in how we design our machines. Buolamwini stated, “there are costs of inclusion and costs of exclusion to be considered in the design and deployment of AI systems that must be contextualized” (Buolamwini 258). Just like the system's Buolamwini critiques, our system could easily exclude unfamiliar or nuanced inputs, not because they were incorrect, but because they weren’t part of the model's narrow training scope.
</p>
    </div>
    <footer>
		© <Span><script type="text/JavaScript">document.write(new Date().getFullYear());</script></Span>
		   LIS500, Inc. All Rights Reserved.
		    <br>
			<br>
		    Nsikan Morgan  |  Rachel Ren 
	</footer>

    </body>
    </html>
