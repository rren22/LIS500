<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h1>Machine Learning</h1>

    <!-- Navigation Bar -->
    <nav>
        <table class="nav-list">
            <td><a href="index.html">Home</a></td>
            <td><a href="aboutus.html">About Us</a></td>
            <td><a href="resources.html">Resources</a></td>
            <td><a href="techhero.html">Tech Heroes</a></td>
            <td><a href="ourmachine.html">Machine Learning</a></td>
            
        </table>
    </nav>

    <nav>

        <a href="ourmachine.html"><button class="MLA-But">Try Our Model</button></a>
        <a href="Objective.html"> <button class="MLA-But">Objective</button></a>
        <a href="Process.html"> <button class="MLA-But">Process</button></a>
        <a href="BuolamwinisWork.html"><button class="MLA-But">Buolamwini's Work</button></a>
        <a href="LessonsLearned.html"> <button class="MLA-But">Lessons Learned</button></a>
        <a href="MLvideo.html"><button class="MLA-But">Video Example</button></a>

    </nav>
<br>

    
   
    <div class="ML-Words">
         <h2>Project Objective & Scope</h2>
    <br>
    <p>Our team, for our machine learning project, aimed to train a model with Google's <strong>Teachable
        Machine</strong> to differentiate between black-and-white origami balls and colored origami balls.
    This rather straightforward visual task enabled us to examine the degree to which accessible tools such
    as Teachable Machine can facilitate image classification without requiring deep programming skills.</p>
<p>But while our technical goal was straightforward—detecting color differences—the larger lesson arrived as
    we wrestled with the social and ethical consequences of algorithmic decision-making. Reading
    <em>Unmasking AI</em> by Joy Buolamwini alongside this project expanded our understanding of what it
    means to design algorithms in a society that is already biased. Buolamwini's research reveals the
    dangers of AI systems that perpetuate racial biases due to the data upon which they are trained. We
    began to understand that even the most "neutral" AI systems are programmed by a set of choices: what
    information we give them, how we label that information, and what outcomes we aim to optimize for.
</p>
</div>
<footer>
    © <Span><script type="text/JavaScript">document.write(new Date().getFullYear());</script></Span>
       LIS500, Inc. All Rights Reserved.
        <br>
        <br>
        Nsikan Morgan  |  Rachel Ren 
</footer>
</body>
</html>
