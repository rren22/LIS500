<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h1>Machine Learning</h1>

    <!-- Navigation Bar -->
    <nav>
        <table class="nav-list">
            <td><a href="index.html">Home</a></td>
            <td><a href="aboutus.html">About Us</a></td>
            <td><a href="resources.html">Resources</a></td>
            <td><a href="techhero.html">Tech Heroes</a></td>
            <td><a href="ourmachine.html">Machine Learning</a></td>
            
        </table>
    </nav>

    <nav>

        <a href="ourmachine.html"><button class="MLA-But">Try Our Model</button></a>
        <a href="Objective.html"> <button class="MLA-But">Objective</button></a>
        <a href="Process.html"> <button class="MLA-But">Process</button></a>
        <a href="BuolamwinisWork.html"><button class="MLA-But">Buolamwini's Work</button></a>
        <a href="LessonsLearned.html"> <button class="MLA-But">Lessons Learned</button></a>
        <a href="MLvideo.html"><button class="MLA-But">Video Example</button></a>

    </nav>
    <br>
   
    <div class="ML-Words">
         <h2>Process</h2>
    <br>
    <p>Our process began with defining what kind of model we would train. We considered building a model around
        sound but ultimately decided on a visual one, reasoning that it would be easier to connect back to our
        coursework on visual bias—specifically racial, appearance, and body presentation bias. While we did talk
        about biases also existing in how people sound (e.g., accent, tone), a visual model allowed us to study
        bias in a more tangible, visual way.</p>
    <div class="image-pair">
        <img src="Black and White Origami Balls.jpg" alt="Black/White Origami Balls">
        <img src="ColorOrigamiBalls.jpg" alt="Color Origami Balls">
    </div>
    
    <p>Once we had chosen a visual model, we had to choose what objects to scan. In contrast to the tutorial
        video illustration, we didn't have many choices readily at hand—so we chose two origami balls: one
        colored, and one black and white. We trained the Teachable Machine to recognize the visual difference
        between the two. While the training process itself was straightforward, installing the model onto our
        website took additional time and debugging. We just copied the tutorial code but had to use additional
        resources to properly interface our trained model and have it show up and work on the webpage. We
        managed to finally get it to run successfully by trial and error.</p>
    </div>
    <footer>
		© <Span><script type="text/JavaScript">document.write(new Date().getFullYear());</script></Span>
		   LIS500, Inc. All Rights Reserved.
		    <br>
			<br>
		    Nsikan Morgan  |  Rachel Ren 
	</footer>
</body>
</html>
