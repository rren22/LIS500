<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h1>Machine Learning</h1>

    <!-- Navigation Bar -->
    <nav>
        <table class="nav-list">
            <td><a href="index.html">Home</a></td>
            <td><a href="aboutus.html">About Us</a></td>
            <td><a href="resources.html">Resources</a></td>
            <td><a href="techhero.html">Tech Heroes</a></td>
            <td><a href="ourmachine.html">Machine Learning</a></td>
            
        </table>
    </nav>

    <nav>

        <a href="ourmachine.html"><button class="MLA-But">Try Our Model</button></a>
        <a href="Objective.html"> <button class="MLA-But">Objective</button></a>
        <a href="Process.html"> <button class="MLA-But">Process</button></a>
        <a href="BuolamwinisWork.html"><button class="MLA-But">Buolamwini's Work</button></a>
        <a href="LessonsLearned.html"> <button class="MLA-But">Lessons Learned</button></a>
        <a href="MLvideo.html"><button class="MLA-But">Video Example</button></a>

    </nav>
    <br>
 
    
    <div class="ML-Words">
       <h2>Lesson Learned</h2>
    <br> 
    <p>Teachable Machine made it simple to build and export a working model, and that is proof of the increased
        accessibility of machine learning tools. But this also presents enormous ethical responsibilities. Just
        because anyone can build an algorithm doesn't necessarily mean every algorithm is built with care or in
        an inclusive way.</p>
    <p>One significant thing we learned is that technology is not value-neutral. Algorithms reflect the values,
        assumptions, and blind spots of their developers. For fairness, diversity at the development stage—the
        people who develop the tools and the data we train on—is key. Ethical concerns must be incorporated into
        the development process from the very beginning of AI development so that these systems do not harm
        unintentionally the very people they are designed to serve.</p>
    <p>Personally, the biggest moment of surprise was realizing just how easily our model would mislabel
        something. If we held in front of the camera a black-and-white object that was not an origami ball, the
        model would refuse to classify it otherwise. This revealed to us just how literal and one-dimensional
        the machine's "comprehension" is—it doesn't know what an origami ball is, only what pixel configurations
        it was shown during training.</p>
    <p>This has deep implications in daily life. Whether it's a facial recognition program that misidentifies
        darker-skinned people, or a hiring algorithm that learns from biased résumés, AI will mirror the gaps,
        omissions, and biases of its training data unless we intervene.</p>
        </div>
        <footer>
            © <Span><script type="text/JavaScript">document.write(new Date().getFullYear());</script></Span>
               LIS500, Inc. All Rights Reserved.
                <br>
                <br>
                Nsikan Morgan  |  Rachel Ren 
        </footer>
</body>
</html>
    
    
